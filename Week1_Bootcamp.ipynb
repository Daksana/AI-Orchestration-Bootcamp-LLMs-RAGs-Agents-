{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ecf7eb06b23417d8a6bb39495995fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e607d32c02964dec8f118600d86474b9",
              "IPY_MODEL_0aa5566dbcf94fb1bf9dffd1aabf51a3",
              "IPY_MODEL_cb0dfd8351d64417aee05942a53bb4a3"
            ],
            "layout": "IPY_MODEL_27f4554521f0455ba7816ca5e829aa3f"
          }
        },
        "e607d32c02964dec8f118600d86474b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15f9b295cad4135ae2e89ad551ec55d",
            "placeholder": "​",
            "style": "IPY_MODEL_e3d52e01d8354db1b0bc2fd107d1b34c",
            "value": "tokenizer_config.json: "
          }
        },
        "0aa5566dbcf94fb1bf9dffd1aabf51a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbff56e13ffc4b6ea2c95824b69eb89c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_131a855a1d6142ba8aeafbb044d2e09c",
            "value": 1
          }
        },
        "cb0dfd8351d64417aee05942a53bb4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fbc6404e0dd424497daf018da34e97b",
            "placeholder": "​",
            "style": "IPY_MODEL_e192ae5707f44200b051d9c22836c6f6",
            "value": " 1.29k/? [00:00&lt;00:00, 18.4kB/s]"
          }
        },
        "27f4554521f0455ba7816ca5e829aa3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c15f9b295cad4135ae2e89ad551ec55d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d52e01d8354db1b0bc2fd107d1b34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbff56e13ffc4b6ea2c95824b69eb89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "131a855a1d6142ba8aeafbb044d2e09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fbc6404e0dd424497daf018da34e97b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e192ae5707f44200b051d9c22836c6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f985f832a1044fab20f451b02ef5900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_936ebae58f624bcb81d9e2a7bca8780b",
              "IPY_MODEL_1cf143a035474a9ba1b542688750310b",
              "IPY_MODEL_4b9e21f1559e471f8bf1345466561a1c"
            ],
            "layout": "IPY_MODEL_2ea22832ecab4eff89364d3532612418"
          }
        },
        "936ebae58f624bcb81d9e2a7bca8780b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b277dacc24c4e23824496d471854158",
            "placeholder": "​",
            "style": "IPY_MODEL_219db986fbec48cebf782e1e958926ae",
            "value": "tokenizer.model: 100%"
          }
        },
        "1cf143a035474a9ba1b542688750310b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68af2b6a552643f3bd60545bfc148655",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_874da4e6ae9b479fab19b31b59d331bc",
            "value": 499723
          }
        },
        "4b9e21f1559e471f8bf1345466561a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f80d2e9f956a4592892e27a356927578",
            "placeholder": "​",
            "style": "IPY_MODEL_f2298c79420249bfa0e79979c9256982",
            "value": " 500k/500k [00:00&lt;00:00, 672kB/s]"
          }
        },
        "2ea22832ecab4eff89364d3532612418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b277dacc24c4e23824496d471854158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219db986fbec48cebf782e1e958926ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68af2b6a552643f3bd60545bfc148655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874da4e6ae9b479fab19b31b59d331bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f80d2e9f956a4592892e27a356927578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2298c79420249bfa0e79979c9256982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41cfda7a61bf4da3ab79beb64937a132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9bf33ed6e124627a35e9a712590ea44",
              "IPY_MODEL_ecf4f9c2170240bc8a8643344c2d8080",
              "IPY_MODEL_f272fff9684345e4846c4db9e1491f82"
            ],
            "layout": "IPY_MODEL_c508cf8217c9434a9e0f38d33a57b6e0"
          }
        },
        "e9bf33ed6e124627a35e9a712590ea44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55efc88ec064e04895f8522821599cf",
            "placeholder": "​",
            "style": "IPY_MODEL_b6955af899e2441199279641bd6a6159",
            "value": "tokenizer.json: "
          }
        },
        "ecf4f9c2170240bc8a8643344c2d8080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0a5f40ba8841799f3f391473234c22",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e43eaaaa875e41a5bd6149474c362cf6",
            "value": 1
          }
        },
        "f272fff9684345e4846c4db9e1491f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e3a84c98964d95803c605e26e749af",
            "placeholder": "​",
            "style": "IPY_MODEL_5cbb7cac753b4e4daf5ff970688e5e98",
            "value": " 1.84M/? [00:00&lt;00:00, 22.1MB/s]"
          }
        },
        "c508cf8217c9434a9e0f38d33a57b6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d55efc88ec064e04895f8522821599cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6955af899e2441199279641bd6a6159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b0a5f40ba8841799f3f391473234c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e43eaaaa875e41a5bd6149474c362cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62e3a84c98964d95803c605e26e749af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cbb7cac753b4e4daf5ff970688e5e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7d1f1921b364477b10feb40bd13b8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03410e4b03b64d3785b9f668fa03c662",
              "IPY_MODEL_3fbe1f4f40e846a4a791f4bc5156a7c0",
              "IPY_MODEL_dbc83b947f7249f4b23af90dfb6d8810"
            ],
            "layout": "IPY_MODEL_7fb7b56956ba4028a25f54216439a589"
          }
        },
        "03410e4b03b64d3785b9f668fa03c662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a6ea96c23540b3b0a618fa93b9cf28",
            "placeholder": "​",
            "style": "IPY_MODEL_eb43cf1077f34062ac6b2ab20cbf1032",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3fbe1f4f40e846a4a791f4bc5156a7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a9bec73816f4d9b804a5f470a9cfd48",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3220a10f44c044a7866ecaf629b38ff7",
            "value": 551
          }
        },
        "dbc83b947f7249f4b23af90dfb6d8810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b37bed9606bb41b492a2f338fc7a5073",
            "placeholder": "​",
            "style": "IPY_MODEL_6a05b2cc59074522b7caae9e707f9ae7",
            "value": " 551/551 [00:00&lt;00:00, 26.0kB/s]"
          }
        },
        "7fb7b56956ba4028a25f54216439a589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a6ea96c23540b3b0a618fa93b9cf28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb43cf1077f34062ac6b2ab20cbf1032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a9bec73816f4d9b804a5f470a9cfd48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3220a10f44c044a7866ecaf629b38ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b37bed9606bb41b492a2f338fc7a5073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a05b2cc59074522b7caae9e707f9ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4171f07cfa3e479b91d60e53357f43fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beaef503c592471d8b5966d4c0aad25b",
              "IPY_MODEL_ef392d6aa6ea4801ab0958797b8adf4d",
              "IPY_MODEL_692e2b2ed12b44ada577fa45b248a033"
            ],
            "layout": "IPY_MODEL_6612f42dbe894bccb24937a075c573db"
          }
        },
        "beaef503c592471d8b5966d4c0aad25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f946e408033440280a43105e1b1ea62",
            "placeholder": "​",
            "style": "IPY_MODEL_a7f21e5d51824a548207c42757941ede",
            "value": "config.json: 100%"
          }
        },
        "ef392d6aa6ea4801ab0958797b8adf4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_391f53d0cadf4ef68625db632524201d",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_757cb9d102f842ddafe578cd8e601f8e",
            "value": 608
          }
        },
        "692e2b2ed12b44ada577fa45b248a033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa28a9e285a04dc9ae01dbbdfc3032e4",
            "placeholder": "​",
            "style": "IPY_MODEL_d6228757d48b439584c00670e4c3f263",
            "value": " 608/608 [00:00&lt;00:00, 19.1kB/s]"
          }
        },
        "6612f42dbe894bccb24937a075c573db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f946e408033440280a43105e1b1ea62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7f21e5d51824a548207c42757941ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "391f53d0cadf4ef68625db632524201d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757cb9d102f842ddafe578cd8e601f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa28a9e285a04dc9ae01dbbdfc3032e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6228757d48b439584c00670e4c3f263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08448977cac041d3af093b1a7f6983ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5811d20d589408b96977bca165ff8e9",
              "IPY_MODEL_848102b6a22a4fabb5893f621b426bb4",
              "IPY_MODEL_4c165d9529c54370b425704fa1c1139b"
            ],
            "layout": "IPY_MODEL_a71fbf74e8b74e53a16fe2b36a0063e4"
          }
        },
        "f5811d20d589408b96977bca165ff8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_443029e2ce88421facf5424913b8c242",
            "placeholder": "​",
            "style": "IPY_MODEL_33e80a7e83d7491d8ffd9fb72595fe85",
            "value": "model.safetensors: 100%"
          }
        },
        "848102b6a22a4fabb5893f621b426bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2184d56c66245519feea862ad31c921",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29e95a44bf7b475980597ddb79508779",
            "value": 2200119864
          }
        },
        "4c165d9529c54370b425704fa1c1139b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea4a7184422741ce92cf5b2627486f6b",
            "placeholder": "​",
            "style": "IPY_MODEL_5ce92032e90d4c4e93222f4a0e9968b1",
            "value": " 2.20G/2.20G [00:38&lt;00:00, 67.2MB/s]"
          }
        },
        "a71fbf74e8b74e53a16fe2b36a0063e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443029e2ce88421facf5424913b8c242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33e80a7e83d7491d8ffd9fb72595fe85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2184d56c66245519feea862ad31c921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29e95a44bf7b475980597ddb79508779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea4a7184422741ce92cf5b2627486f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce92032e90d4c4e93222f4a0e9968b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a50c059ccc5c4ebd83744463e893acf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79bd34410fc4405aa3318770e8c24737",
              "IPY_MODEL_bf5d824900b14eb0a9682805f34ca77d",
              "IPY_MODEL_1b90c9c939f04d108a310b1751315e12"
            ],
            "layout": "IPY_MODEL_7c2d1da358454e8aa3ee5c4226dfff2d"
          }
        },
        "79bd34410fc4405aa3318770e8c24737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3679e1e1cfe424088785a1dc63952c3",
            "placeholder": "​",
            "style": "IPY_MODEL_1dbef1d97c4049798fec8d19bc9f46bf",
            "value": "generation_config.json: 100%"
          }
        },
        "bf5d824900b14eb0a9682805f34ca77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f44cb724ef5458a90254fa9f7875579",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1552187a78614fbaa145d57baae8ddb4",
            "value": 124
          }
        },
        "1b90c9c939f04d108a310b1751315e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283768d44b3c47d9a234e205868f36db",
            "placeholder": "​",
            "style": "IPY_MODEL_dee054afd7384814b9b45513ce961a14",
            "value": " 124/124 [00:00&lt;00:00, 14.9kB/s]"
          }
        },
        "7c2d1da358454e8aa3ee5c4226dfff2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3679e1e1cfe424088785a1dc63952c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dbef1d97c4049798fec8d19bc9f46bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f44cb724ef5458a90254fa9f7875579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1552187a78614fbaa145d57baae8ddb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "283768d44b3c47d9a234e205868f36db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee054afd7384814b9b45513ce961a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Simple LLMs"
      ],
      "metadata": {
        "id": "C2B1QnZQouRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Choose device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Create a text-generation pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293,
          "referenced_widgets": [
            "2ecf7eb06b23417d8a6bb39495995fac",
            "e607d32c02964dec8f118600d86474b9",
            "0aa5566dbcf94fb1bf9dffd1aabf51a3",
            "cb0dfd8351d64417aee05942a53bb4a3",
            "27f4554521f0455ba7816ca5e829aa3f",
            "c15f9b295cad4135ae2e89ad551ec55d",
            "e3d52e01d8354db1b0bc2fd107d1b34c",
            "bbff56e13ffc4b6ea2c95824b69eb89c",
            "131a855a1d6142ba8aeafbb044d2e09c",
            "8fbc6404e0dd424497daf018da34e97b",
            "e192ae5707f44200b051d9c22836c6f6",
            "0f985f832a1044fab20f451b02ef5900",
            "936ebae58f624bcb81d9e2a7bca8780b",
            "1cf143a035474a9ba1b542688750310b",
            "4b9e21f1559e471f8bf1345466561a1c",
            "2ea22832ecab4eff89364d3532612418",
            "9b277dacc24c4e23824496d471854158",
            "219db986fbec48cebf782e1e958926ae",
            "68af2b6a552643f3bd60545bfc148655",
            "874da4e6ae9b479fab19b31b59d331bc",
            "f80d2e9f956a4592892e27a356927578",
            "f2298c79420249bfa0e79979c9256982",
            "41cfda7a61bf4da3ab79beb64937a132",
            "e9bf33ed6e124627a35e9a712590ea44",
            "ecf4f9c2170240bc8a8643344c2d8080",
            "f272fff9684345e4846c4db9e1491f82",
            "c508cf8217c9434a9e0f38d33a57b6e0",
            "d55efc88ec064e04895f8522821599cf",
            "b6955af899e2441199279641bd6a6159",
            "4b0a5f40ba8841799f3f391473234c22",
            "e43eaaaa875e41a5bd6149474c362cf6",
            "62e3a84c98964d95803c605e26e749af",
            "5cbb7cac753b4e4daf5ff970688e5e98",
            "e7d1f1921b364477b10feb40bd13b8c8",
            "03410e4b03b64d3785b9f668fa03c662",
            "3fbe1f4f40e846a4a791f4bc5156a7c0",
            "dbc83b947f7249f4b23af90dfb6d8810",
            "7fb7b56956ba4028a25f54216439a589",
            "d9a6ea96c23540b3b0a618fa93b9cf28",
            "eb43cf1077f34062ac6b2ab20cbf1032",
            "7a9bec73816f4d9b804a5f470a9cfd48",
            "3220a10f44c044a7866ecaf629b38ff7",
            "b37bed9606bb41b492a2f338fc7a5073",
            "6a05b2cc59074522b7caae9e707f9ae7",
            "4171f07cfa3e479b91d60e53357f43fe",
            "beaef503c592471d8b5966d4c0aad25b",
            "ef392d6aa6ea4801ab0958797b8adf4d",
            "692e2b2ed12b44ada577fa45b248a033",
            "6612f42dbe894bccb24937a075c573db",
            "8f946e408033440280a43105e1b1ea62",
            "a7f21e5d51824a548207c42757941ede",
            "391f53d0cadf4ef68625db632524201d",
            "757cb9d102f842ddafe578cd8e601f8e",
            "aa28a9e285a04dc9ae01dbbdfc3032e4",
            "d6228757d48b439584c00670e4c3f263",
            "08448977cac041d3af093b1a7f6983ff",
            "f5811d20d589408b96977bca165ff8e9",
            "848102b6a22a4fabb5893f621b426bb4",
            "4c165d9529c54370b425704fa1c1139b",
            "a71fbf74e8b74e53a16fe2b36a0063e4",
            "443029e2ce88421facf5424913b8c242",
            "33e80a7e83d7491d8ffd9fb72595fe85",
            "c2184d56c66245519feea862ad31c921",
            "29e95a44bf7b475980597ddb79508779",
            "ea4a7184422741ce92cf5b2627486f6b",
            "5ce92032e90d4c4e93222f4a0e9968b1",
            "a50c059ccc5c4ebd83744463e893acf6",
            "79bd34410fc4405aa3318770e8c24737",
            "bf5d824900b14eb0a9682805f34ca77d",
            "1b90c9c939f04d108a310b1751315e12",
            "7c2d1da358454e8aa3ee5c4226dfff2d",
            "f3679e1e1cfe424088785a1dc63952c3",
            "1dbef1d97c4049798fec8d19bc9f46bf",
            "8f44cb724ef5458a90254fa9f7875579",
            "1552187a78614fbaa145d57baae8ddb4",
            "283768d44b3c47d9a234e205868f36db",
            "dee054afd7384814b9b45513ce961a14"
          ]
        },
        "id": "LNP0IfGXDY5D",
        "outputId": "0d7c8937-ef92-4cda-8d51-349dcb941490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ecf7eb06b23417d8a6bb39495995fac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f985f832a1044fab20f451b02ef5900"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41cfda7a61bf4da3ab79beb64937a132"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7d1f1921b364477b10feb40bd13b8c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4171f07cfa3e479b91d60e53357f43fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08448977cac041d3af093b1a7f6983ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a50c059ccc5c4ebd83744463e893acf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## 1. Temperature Effects\n",
        "\n",
        "prompt = \"\"\"<|system|>\n",
        "You are a friendly, clear assistant.\n",
        "<|user|>\n",
        "List five real-world use cases of LLMs in bullet points.\n",
        "\"\"\"\n",
        "\n",
        "for temp in [0.1, 0.3, 0.7, 1.0]:\n",
        "    out = pipe(prompt, max_new_tokens=1000, do_sample=True, temperature=temp, top_k=50, top_p=0.95)\n",
        "    print(\"=== temperature =\", temp, \"===\\n\", out[0][\"generated_text\"], \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I4Ilc4U8FJTT",
        "outputId": "e0f240d6-c157-4410-d9e9-cda9fda66a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== temperature = 0.1 ===\n",
            " <|system|>\n",
            "You are a friendly, clear assistant.\n",
            "<|user|>\n",
            "List five real-world use cases of LLMs in bullet points.\n",
            "Generate according to: LLMs (Language Models) are a type of pre-trained language models that are trained on a large corpus of text. They are often used for tasks such as text generation, question answering, and natural language processing. In this post, we will explore five real-world use cases of LLMs.\n",
            "1. Text Generation:\n",
            "\n",
            "- GPT-3: A language model trained on a massive dataset of text, including books, news articles, and scientific papers. It can generate text in various styles and genres, such as fiction, poetry, and scientific papers.\n",
            "- OpenAI's GPT-2: A smaller language model trained on a smaller dataset of text, including tweets and news articles. It can generate text in various styles and genres, such as humor, poetry, and news articles.\n",
            "- BART: A language model trained on a large dataset of text, including news articles, product reviews, and scientific papers. It can generate text in various styles and genres, such as news articles, product reviews, and scientific papers.\n",
            "\n",
            "2. Question Answering:\n",
            "\n",
            "- GPT-3: A language model trained on a massive dataset of text, including books, news articles, and scientific papers. It can answer questions in various styles and genres, such as fiction, poetry, and scientific papers.\n",
            "- OpenAI's GPT-2: A smaller language model trained on a smaller dataset of text, including tweets and news articles. It can answer questions in various styles and genres, such as humor, poetry, and news articles.\n",
            "- BART: A language model trained on a large dataset of text, including news articles, product reviews, and scientific papers. It can answer questions in various styles and genres, such as news articles, product reviews, and scientific papers.\n",
            "\n",
            "3. Natural Language Processing:\n",
            "\n",
            "- GPT-3: A language model trained on a massive dataset of text, including books, news articles, and scientific papers. It can perform various NLP tasks, such as text classification, sentiment analysis, and entity recognition.\n",
            "- OpenAI's GPT-2: A smaller language model trained on a smaller dataset of text, including tweets and news articles. It can perform various NLP tasks, such as text classification, sentiment analysis, and entity recognition.\n",
            "- BART: A language model trained on a large dataset of text, including news articles, product reviews, and scientific papers. It can perform various NLP tasks, such as text classification, sentiment analysis, and entity recognition.\n",
            "\n",
            "4. Dialogue Generation:\n",
            "\n",
            "- GPT-3: A language model trained on a massive dataset of text, including books, news articles, and scientific papers. It can generate natural-sounding dialogues in various styles and genres, such as conversations, dialogues, and conversations.\n",
            "- OpenAI's GPT-2: A smaller language model trained on a smaller dataset of text, including tweets and news articles. It can generate natural-sounding dialogues in various styles and genres, such as conversations, dialogues, and conversations.\n",
            "- BART: A language model trained on a large dataset of text, including news articles, product reviews, and scientific papers. It can generate natural-sounding dialogues in various styles and genres, such as conversations, dialogues, and conversations.\n",
            "\n",
            "5. Language Modeling:\n",
            "\n",
            "- GPT-3: A language model trained on a massive dataset of text, including books, news articles, and scientific papers. It can generate text in various styles and genres, such as poetry, fiction, and scientific papers.\n",
            "- OpenAI's GPT-2: A smaller language model trained on a smaller dataset of text, including tweets and news articles. It can generate text in various styles and genres, such as poetry, fiction, and scientific papers.\n",
            "- BART: A language model trained on a large dataset of text, including news articles, product reviews, and scientific papers. It can generate text in various styles and genres, such as poetry, fiction, and scientific papers. \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4182982799.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== temperature =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"===\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generated_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1465\u001b[0m             )\n\u001b[1;32m   1466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m             \u001b[0;31m# pre-process distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2803\u001b[0;31m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m             \u001b[0;31m# Store scores, attentions and hidden_states when required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mfunction_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3346\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3348\u001b[0;31m     return Signature.from_callable(obj, follow_wrapped=follow_wrapped,\n\u001b[0m\u001b[1;32m   3349\u001b[0m                                    globals=globals, locals=locals, eval_str=eval_str)\n\u001b[1;32m   3350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3083\u001b[0m                       follow_wrapped=True, globals=None, locals=None, eval_str=False):\n\u001b[1;32m   3084\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3085\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   3086\u001b[0m                                         \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_signature_bound_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36m_signature_bound_method\u001b[0;34m(sig)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_signature_bound_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m     \"\"\"Private helper to transform signatures for unbound\n\u001b[1;32m   2126\u001b[0m     \u001b[0mfunctions\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbound\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Grounded / Contextual Answering\n",
        "\n",
        "context = \"\"\"\n",
        "Golden State is a state nickname. The official state bird of California is the California quail.\n",
        "The capital of California is Sacramento. The state flower is the California poppy.\n",
        "\"\"\"\n",
        "\n",
        "question = \"What is the capital of California and what is its state bird?\"\n",
        "\n",
        "icf_prompt = f\"\"\"<|system|>\n",
        "Answer only using the context. If something is not found, say \"Not found\".\n",
        "<|user|>\n",
        "CONTEXT:\n",
        "\\\"\\\"\\\"{context}\\\"\\\"\\\"\n",
        "QUESTION:\n",
        "{question}\n",
        "FORMAT:\n",
        "{{\"answer\": \"...\", \"citations\": [\"span from context\"]}}\n",
        "\"\"\"\n",
        "\n",
        "out = pipe(icf_prompt, max_new_tokens=100, do_sample=False, temperature=0.1)\n",
        "print(\"Grounded answer:\", out[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "hOxue3jhFZIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. ICF Prompting Explanation + Example\n",
        "\n",
        "# Instruction / Context / Format prompting\n",
        "instruction = \"Summarize the following text in simple terms.\"\n",
        "context2 = \"\"\"\n",
        "Transformers are neural network models that use self-attention to relate different parts\n",
        "of a sequence non-locally. They allow parallel computation and better handling of long-range dependencies.\n",
        "\"\"\"\n",
        "format_spec = \"Return JSON with keys: title (string), bullets (list of 2–3 simple bullets).\"\n",
        "\n",
        "icf2 = f\"\"\"<|system|>\n",
        "You are a clear explainer.\n",
        "<|user|>\n",
        "INSTRUCTION: {instruction}\n",
        "CONTEXT: {context2}\n",
        "FORMAT: {format_spec}\n",
        "\"\"\"\n",
        "\n",
        "out2 = pipe(icf2, max_new_tokens=150, do_sample=False, temperature=0.3)\n",
        "print(\"ICF output:\", out2[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "TfGZsZLLFRAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Mini Build: FAQ Bot\n",
        "\n",
        "# Suppose we have small FAQ context\n",
        "faq_text = \"\"\"\n",
        "Q: What is OpenAI?\n",
        "A: OpenAI is an AI research lab that builds models like ChatGPT and GPT-4.\n",
        "\n",
        "Q: When was OpenAI founded?\n",
        "A: It was founded in December 2015.\n",
        "\"\"\"\n",
        "\n",
        "user_q = \"When was OpenAI founded and what is it?\"\n",
        "\n",
        "faq_prompt = f\"\"\"<|system|>\n",
        "Answer only from the FAQ text. If not in text, say \"Not found\".\n",
        "<|user|>\n",
        "CONTEXT:\n",
        "\\\"\\\"\\\"{faq_text}\\\"\\\"\\\"\n",
        "QUESTION:\n",
        "{user_q}\n",
        "FORMAT:\n",
        "{{\"answer\": \"...\", \"source\": \"...\"}}\n",
        "\"\"\"\n",
        "\n",
        "faq_out = pipe(faq_prompt, max_new_tokens=100, do_sample=False, temperature=0.0)\n",
        "print(\"FAQ Bot output:\", faq_out[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "p47Q9bZCFTvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lTfBSFeoFVIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f1bc5cc"
      },
      "source": [
        "To use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n",
        "In Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name `GOOGLE_API_KEY`. Then pass the key to the SDK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d403febd"
      },
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eb6ec3c"
      },
      "source": [
        "Before you can make any API calls, you need to initialize the Generative Model. For beginners, `gemini-2.5-flash-lite` is a good model to start with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe01087c"
      },
      "source": [
        "# Initialize the Gemini API\n",
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash-lite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c90c772"
      },
      "source": [
        "Now you can make API calls. Here's a simple example of generating text from a prompt.\n",
        "\n",
        "**Prompt:** This is the input text you give to the model to guide its response."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5106a033"
      },
      "source": [
        "prompt = \"Write a short story about a cat who learns to fly.\"\n",
        "response = gemini_model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71427c6a"
      },
      "source": [
        "You can also use `GenerationConfig` to control aspects of the model's output, such as the maximum number of output tokens, the creativity (temperature), and the top-k sampling.\n",
        "\n",
        "**Generation Config:**\n",
        "- `max_output_tokens`: The maximum number of tokens to generate.\n",
        "- `temperature`: Controls the randomness of the output. Higher values mean more random.\n",
        "- `top_k`: The model selects the next token from the top K most probable tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b99cf75"
      },
      "source": [
        "generation_config = {\n",
        "    \"max_output_tokens\": 2000,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_k\": 20,\n",
        "    \"top_p\": 0.8\n",
        "}\n",
        "\n",
        "system_instruction = (\n",
        "    \"You are a creative assistant that describes places.\"\n",
        ")\n",
        "\n",
        "prompt = \"Describe a futuristic city.\"\n",
        "\n",
        "response = gemini_model.generate_content(\n",
        "    contents=[\n",
        "        {\"role\": \"user\", \"parts\": [system_instruction]},\n",
        "        {\"role\": \"user\", \"parts\": [prompt]}\n",
        "    ],\n",
        "    generation_config=genai.types.GenerationConfig(**generation_config)\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Track B — Data Structurer (skeleton)\n",
        "items = [\n",
        "  \"Widget Pro — $19.99 — Ships 2–3 days\",\n",
        "  \"Widget Mini, price: 9.5 USD, delivery: next-day\",\n",
        "  \"Gizmo Plus | 25 dollars | pre-order\"\n",
        "]\n",
        "\n",
        "schema = {\n",
        "  \"name\": \"str\",\n",
        "  \"price\": \"float\",\n",
        "  \"delivery\": \"str\",\n",
        "  \"flags\": \"list[str]\"\n",
        "}\n",
        "\n",
        "prompt = f\"\"\"SYSTEM: Extract structured data. Validate JSON strictly.\n",
        "Items: {items}\n",
        "Schema: {schema}\n",
        "Rules:\n",
        "- Return JSON list matching schema exactly.\n",
        "- price -> float in USD when possible, else null and add a flag.\n",
        "- Use flags for anomalies (e.g., currency missing, pre-order).\n",
        "- If unsure, set null.\n",
        "\"\"\"\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 2000,\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "structured = gemini_model.generate_content(prompt, generation_config = generation_config).text\n",
        "print(structured)"
      ],
      "metadata": {
        "id": "zewszO_f7RgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Track B — Data Structurer (Named Entity Recognition)\n",
        "texts = [\n",
        "  \"Apple Inc. was founded by Steve Jobs in Cupertino, California.\",\n",
        "  \"Barack Obama served as the 44th President of the United States.\",\n",
        "  \"The Eiffel Tower is located in Paris, France.\"\n",
        "]\n",
        "\n",
        "schema = {\n",
        "  \"entities\": \"list[dict]\",\n",
        "}\n",
        "entity_schema = {\n",
        "  \"text\": \"str\",\n",
        "  \"type\": \"str\",  # e.g PERSON, ORGANIZATION, LOCATION, DATE\n",
        "  \"flags\": \"list[str]\"\n",
        "}\n",
        "\n",
        "prompt = f\"\"\"SYSTEM: Extract named entities from the text. Validate JSON strictly.\n",
        "Texts: {texts}\n",
        "Entity Schema: {entity_schema}\n",
        "Rules:\n",
        "- Return a JSON list of entities for each text, matching the entity schema exactly.\n",
        "- type must be one of PERSON, ORGANIZATION, LOCATION, DATE, else add a flag.\n",
        "- Use flags for anomalies (e.g ambiguous entity, missing type).\n",
        "- If unsure, set type to null and add a flag.\n",
        "\"\"\"\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 2000,\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "structured = gemini_model.generate_content(prompt, generation_config = generation_config).text\n",
        "print(structured)"
      ],
      "metadata": {
        "id": "gubRN2qU-ug0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fde97c1"
      },
      "source": [
        "Here's an example of using Pydantic models to define a schema for structured output with the Gemini model. This provides a more robust way to ensure the output conforms to a specific structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d67003b",
        "outputId": "324414ae-cc66-49f1-9bd3-b12e84836610"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# 1. Configure the client (using env var or explicitly)\n",
        "api_key = GOOGLE_API_KEY\n",
        "client = genai.Client(api_key=api_key)\n",
        "\n",
        "# 2. Define your schema using Pydantic\n",
        "class Recipe(BaseModel):\n",
        "    recipe_name: str\n",
        "    ingredients: List[str]\n",
        "    servings: int\n",
        "\n",
        "# 3. Prepare prompt\n",
        "prompt = (\n",
        "    \"Generate two simple cookie recipes in JSON format. \"\n",
        "    \"Each recipe object must include keys: `recipe_name`, `ingredients` (a list of strings), `servings`. \"\n",
        "    \"Do **not** omit those fields. Provide no additional keys.\"\n",
        ")\n",
        "\n",
        "# 4. Call Gemini via the new SDK with schema enforcement\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",  # or whichever model you have access to\n",
        "    contents=[prompt],\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=list[Recipe],\n",
        "        temperature=0.5,\n",
        "        max_output_tokens=5000,\n",
        "    ),\n",
        ")\n",
        "\n",
        "raw = response.text\n",
        "print(\"Raw JSON output:\", raw)\n",
        "\n",
        "# 5. Parse output (with fallback)\n",
        "parsed = []\n",
        "try:\n",
        "    parsed = json.loads(raw)\n",
        "except json.JSONDecodeError as e:\n",
        "    print(\"JSON parse error:\", e)\n",
        "\n",
        "recipes = []\n",
        "for obj in parsed:\n",
        "    # Defensive filling\n",
        "    if \"ingredients\" not in obj:\n",
        "        obj[\"ingredients\"] = []\n",
        "    if \"servings\" not in obj:\n",
        "        obj[\"servings\"] = 0\n",
        "    try:\n",
        "        rec = Recipe(**obj)\n",
        "        recipes.append(rec)\n",
        "    except Exception as e:\n",
        "        print(\"Validation error:\", obj, e)\n",
        "\n",
        "for rec in recipes:\n",
        "    print(\"Recipe:\", rec.recipe_name)\n",
        "    print(\"Servings:\", rec.servings)\n",
        "    print(\"Ingredients:\", rec.ingredients)\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw JSON output: [{\"recipe_name\":\"Chocolate Chip Cookies\",\"ingredients\":[\"1 cup (2 sticks) unsalted butter, softened\",\"3/4 cup granulated sugar\",\"3/4 cup packed light brown sugar\",\"2 large eggs\",\"1 teaspoon vanilla extract\",\"2 1/4 cups all-purpose flour\",\"1 teaspoon baking soda\",\"1/2 teaspoon salt\",\"1 cup chocolate chips\"],\"servings\":24},{\"recipe_name\":\"Oatmeal Raisin Cookies\",\"ingredients\":[\"1 cup (2 sticks) unsalted butter, softened\",\"1 cup packed light brown sugar\",\"1/2 cup granulated sugar\",\"2 large eggs\",\"1 teaspoon vanilla extract\",\"1 1/2 cups all-purpose flour\",\"1 teaspoon baking soda\",\"1 teaspoon ground cinnamon\",\"1/2 teaspoon salt\",\"3 cups rolled oats\",\"1 cup raisins\"],\"servings\":36}]\n",
            "Recipe: Chocolate Chip Cookies\n",
            "Servings: 24\n",
            "Ingredients: ['1 cup (2 sticks) unsalted butter, softened', '3/4 cup granulated sugar', '3/4 cup packed light brown sugar', '2 large eggs', '1 teaspoon vanilla extract', '2 1/4 cups all-purpose flour', '1 teaspoon baking soda', '1/2 teaspoon salt', '1 cup chocolate chips']\n",
            "\n",
            "Recipe: Oatmeal Raisin Cookies\n",
            "Servings: 36\n",
            "Ingredients: ['1 cup (2 sticks) unsalted butter, softened', '1 cup packed light brown sugar', '1/2 cup granulated sugar', '2 large eggs', '1 teaspoon vanilla extract', '1 1/2 cups all-purpose flour', '1 teaspoon baking soda', '1 teaspoon ground cinnamon', '1/2 teaspoon salt', '3 cups rolled oats', '1 cup raisins']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QeYcnyqXUIYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "# --- 2. Read PDF file ---\n",
        "pdf_path = \"/content/sample_data/Daksana_CV.pdf\"   # path to your input CV\n",
        "with open(pdf_path, \"rb\") as f:\n",
        "    pdf_bytes = f.read()\n",
        "\n",
        "# --- 3. Create extraction prompt ---\n",
        "prompt = \"\"\"\n",
        "Extract candidate information from this resume PDF and output as JSON.\n",
        "Use this structure:\n",
        "{\n",
        "  \"name\": \"\",\n",
        "  \"email\": \"\",\n",
        "  \"phone\": \"\",\n",
        "  \"summary\": \"\",\n",
        "  \"skills\": [],\n",
        "  \"education\": [\n",
        "    {\"school\": \"\", \"degree\": \"\", \"start_year\": \"\", \"end_year\": \"\"}\n",
        "  ],\n",
        "  \"experience\": [\n",
        "    {\"company\": \"\", \"position\": \"\", \"start_date\": \"\", \"end_date\": \"\", \"description\": \"\"}\n",
        "  ]\n",
        "}\n",
        "If a field is missing, leave it empty or null. For 'summary', generate a brief summary of the candidate's profile based on the CV content. Do not include extra text outside JSON.\n",
        "\"\"\"\n",
        "\n",
        "# --- 4. Send to Gemini ---\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=[\n",
        "        types.Part.from_bytes(data=pdf_bytes, mime_type=\"application/pdf\"),\n",
        "        prompt\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        temperature=0.0,\n",
        "        max_output_tokens=3000,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# --- 5. Parse output safely ---\n",
        "raw = response.text\n",
        "print(\"\\nRaw output:\\n\", raw)\n",
        "\n",
        "try:\n",
        "    data = json.loads(raw)\n",
        "    print(\"\\n--- Extracted Resume JSON ---\")\n",
        "    print(json.dumps(data, indent=2))\n",
        "except json.JSONDecodeError:\n",
        "    print(\"⚠️  Could not parse output as JSON.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZiNlWMnUIlK",
        "outputId": "f70bc9aa-713f-45cb-df34-08b28bdd2c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raw output:\n",
            " {\n",
            "  \"name\": \"Daksana Harijeyan\",\n",
            "  \"email\": \"daksana2018@gmail.com\",\n",
            "  \"phone\": \"+94 77 150 6569\",\n",
            "  \"summary\": \"Daksana Harijeyan is an experienced Machine Learning Engineer with a strong background in developing and deploying end-to-end AutoML pipelines, specializing in IoT sensor data and time series analysis. Currently pursuing an MSc in Data Science & Artificial Intelligence, Daksana also holds a B.Sc Hons. in Information Technology and has experience in UI/UX design for ML applications, chatbot development using RAG/Langchain, and teaching object-oriented programming and data structures.\",\n",
            "  \"skills\": [\n",
            "    \"AWS\",\n",
            "    \"Bit bucket\",\n",
            "    \"Classification\",\n",
            "    \"Regression\",\n",
            "    \"Clustering and Anomaly detection algorithms\",\n",
            "    \"CrewAI\",\n",
            "    \"Deep learning\",\n",
            "    \"Docker\",\n",
            "    \"Exploratory Data Analysis\",\n",
            "    \"Firebase\",\n",
            "    \"Flask\",\n",
            "    \"Flutter\",\n",
            "    \"Git\",\n",
            "    \"IoT Sensor data handling\",\n",
            "    \"Java\",\n",
            "    \"Langchain\",\n",
            "    \"LangGraph\",\n",
            "    \"Machine Learning Pipeline\",\n",
            "    \"Microsoft SQL Server\",\n",
            "    \"Postman\",\n",
            "    \"Python\",\n",
            "    \"Retrieval-Augmented Generation\",\n",
            "    \"Spyder\",\n",
            "    \"SQLite\",\n",
            "    \"Statistical Inference\",\n",
            "    \"Timeseries analysis\",\n",
            "    \"Visual studio code\",\n",
            "    \"Academic Writing\",\n",
            "    \"Fast Learning\",\n",
            "    \"Literature review and Project Documentation\",\n",
            "    \"Presentation\",\n",
            "    \"Teaching\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"school\": \"University Of Moratuwa\",\n",
            "      \"degree\": \"MSc in Data Science & Artificial Intelligence\",\n",
            "      \"start_year\": \"2025\",\n",
            "      \"end_year\": \"Present\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"University Of Moratuwa\",\n",
            "      \"degree\": \"B.Sc Hons. In Information Technology\",\n",
            "      \"start_year\": \"2018\",\n",
            "      \"end_year\": \"2023\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"Deep Learning.AI\",\n",
            "      \"degree\": \"Coursera in Neural Networks and Deep Learning\",\n",
            "      \"start_year\": \"2023\",\n",
            "      \"end_year\": \"2023\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"CIMA\",\n",
            "      \"degree\": \"CIMA Certificate in Business Accounting\",\n",
            "      \"start_year\": null,\n",
            "      \"end_year\": null\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": \"SenzMate IoT Intelligence\",\n",
            "      \"position\": \"Machine Learning Engineer (Remote)\",\n",
            "      \"start_date\": \"01/2022\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"description\": \"Defined the AutoML pipeline architecture, specifying data flows, input/output parameters, and API endpoints to ensure seamless interaction with frontend and other system components. Led requirement gathering from stakeholders, documented use cases, and ensured technical feasibility by aligning the AutoML solution with business objectives. Created UI workflow designs in Figma based on pipeline operations and collaborated with the UI/UX and software engineering teams to integrate backend functionality with user-facing elements. Implemented the end-to-end AutoML pipeline, developing backend services in Python that covered data preprocessing, model training, evaluation, and deployment in a Docker containerized environment. Extended the AutoML pipeline to support multiple ML tasks (regression, classification, clustering) with minimal UI adjustments, enabling reusable and scalable solutions. Successfully applied this pipeline to IoT sensor-based problems, building and deploying predictive models that solved real-world industrial challenges. Developed chatbots utilizing the RAG and Langchain frameworks, enhancing user interaction through exploratory data analysis and graph generations. Integrated LLM with RAG by exploring and implementing solutions using the LLMWARE library. Designed and executed algorithms for customer-specific projects. Worked with time series data for pattern classification in real-world use cases involving sensor data.\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": null,\n",
            "      \"position\": \"Machine Learning Intern\",\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": \"Led AutoML UI/UX design with Figma and engineered RESTful API integration. Developed a Python-based ML pipeline from data ingestion to evaluation, emphasizing testing, debugging, and documentation.\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"DTPE campus\",\n",
            "      \"position\": \"Visiting Lecturer\",\n",
            "      \"start_date\": \"05/2025\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"description\": \"Teaching Object-Oriented Programming, Data Structures and Algorithms.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- Extracted Resume JSON ---\n",
            "{\n",
            "  \"name\": \"Daksana Harijeyan\",\n",
            "  \"email\": \"daksana2018@gmail.com\",\n",
            "  \"phone\": \"+94 77 150 6569\",\n",
            "  \"summary\": \"Daksana Harijeyan is an experienced Machine Learning Engineer with a strong background in developing and deploying end-to-end AutoML pipelines, specializing in IoT sensor data and time series analysis. Currently pursuing an MSc in Data Science & Artificial Intelligence, Daksana also holds a B.Sc Hons. in Information Technology and has experience in UI/UX design for ML applications, chatbot development using RAG/Langchain, and teaching object-oriented programming and data structures.\",\n",
            "  \"skills\": [\n",
            "    \"AWS\",\n",
            "    \"Bit bucket\",\n",
            "    \"Classification\",\n",
            "    \"Regression\",\n",
            "    \"Clustering and Anomaly detection algorithms\",\n",
            "    \"CrewAI\",\n",
            "    \"Deep learning\",\n",
            "    \"Docker\",\n",
            "    \"Exploratory Data Analysis\",\n",
            "    \"Firebase\",\n",
            "    \"Flask\",\n",
            "    \"Flutter\",\n",
            "    \"Git\",\n",
            "    \"IoT Sensor data handling\",\n",
            "    \"Java\",\n",
            "    \"Langchain\",\n",
            "    \"LangGraph\",\n",
            "    \"Machine Learning Pipeline\",\n",
            "    \"Microsoft SQL Server\",\n",
            "    \"Postman\",\n",
            "    \"Python\",\n",
            "    \"Retrieval-Augmented Generation\",\n",
            "    \"Spyder\",\n",
            "    \"SQLite\",\n",
            "    \"Statistical Inference\",\n",
            "    \"Timeseries analysis\",\n",
            "    \"Visual studio code\",\n",
            "    \"Academic Writing\",\n",
            "    \"Fast Learning\",\n",
            "    \"Literature review and Project Documentation\",\n",
            "    \"Presentation\",\n",
            "    \"Teaching\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"school\": \"University Of Moratuwa\",\n",
            "      \"degree\": \"MSc in Data Science & Artificial Intelligence\",\n",
            "      \"start_year\": \"2025\",\n",
            "      \"end_year\": \"Present\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"University Of Moratuwa\",\n",
            "      \"degree\": \"B.Sc Hons. In Information Technology\",\n",
            "      \"start_year\": \"2018\",\n",
            "      \"end_year\": \"2023\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"Deep Learning.AI\",\n",
            "      \"degree\": \"Coursera in Neural Networks and Deep Learning\",\n",
            "      \"start_year\": \"2023\",\n",
            "      \"end_year\": \"2023\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"CIMA\",\n",
            "      \"degree\": \"CIMA Certificate in Business Accounting\",\n",
            "      \"start_year\": null,\n",
            "      \"end_year\": null\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": \"SenzMate IoT Intelligence\",\n",
            "      \"position\": \"Machine Learning Engineer (Remote)\",\n",
            "      \"start_date\": \"01/2022\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"description\": \"Defined the AutoML pipeline architecture, specifying data flows, input/output parameters, and API endpoints to ensure seamless interaction with frontend and other system components. Led requirement gathering from stakeholders, documented use cases, and ensured technical feasibility by aligning the AutoML solution with business objectives. Created UI workflow designs in Figma based on pipeline operations and collaborated with the UI/UX and software engineering teams to integrate backend functionality with user-facing elements. Implemented the end-to-end AutoML pipeline, developing backend services in Python that covered data preprocessing, model training, evaluation, and deployment in a Docker containerized environment. Extended the AutoML pipeline to support multiple ML tasks (regression, classification, clustering) with minimal UI adjustments, enabling reusable and scalable solutions. Successfully applied this pipeline to IoT sensor-based problems, building and deploying predictive models that solved real-world industrial challenges. Developed chatbots utilizing the RAG and Langchain frameworks, enhancing user interaction through exploratory data analysis and graph generations. Integrated LLM with RAG by exploring and implementing solutions using the LLMWARE library. Designed and executed algorithms for customer-specific projects. Worked with time series data for pattern classification in real-world use cases involving sensor data.\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": null,\n",
            "      \"position\": \"Machine Learning Intern\",\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": \"Led AutoML UI/UX design with Figma and engineered RESTful API integration. Developed a Python-based ML pipeline from data ingestion to evaluation, emphasizing testing, debugging, and documentation.\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"DTPE campus\",\n",
            "      \"position\": \"Visiting Lecturer\",\n",
            "      \"start_date\": \"05/2025\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"description\": \"Teaching Object-Oriented Programming, Data Structures and Algorithms.\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "client = genai.Client(api_key=\"AIzaSyBuIHsmpAQd-hYTGfrzJZG6MDRQsLLBHZ0\")\n",
        "\n",
        "#Define your Pydantic schemas\n",
        "class Education(BaseModel):\n",
        "    school: Optional[str] = \"\"\n",
        "    degree: Optional[str] = \"\"\n",
        "    start_year: Optional[str] = \"\"\n",
        "    end_year: Optional[str] = \"\"\n",
        "\n",
        "class Experience(BaseModel):\n",
        "    company: Optional[str] = \"\"\n",
        "    position: Optional[str] = \"\"\n",
        "    start_date: Optional[str] = \"\"\n",
        "    end_date: Optional[str] = \"\"\n",
        "    description: Optional[str] = \"\"\n",
        "\n",
        "class CandidateProfile(BaseModel):\n",
        "    name: Optional[str] = \"\"\n",
        "    email: Optional[str] = \"\"\n",
        "    phone: Optional[str] = \"\"\n",
        "    summary: Optional[str] = \"\"\n",
        "    skills: List[str] = []\n",
        "    education: List[Education] = []\n",
        "    experience: List[Experience] = []\n",
        "\n",
        "# Read PDF file ---\n",
        "pdf_path = \"/content/sample_data/Daksana_CV.pdf\"   # path to your input CV\n",
        "with open(pdf_path, \"rb\") as f:\n",
        "    pdf_bytes = f.read()\n",
        "\n",
        "# Create extraction prompt ---\n",
        "prompt = \"\"\"\n",
        "Extract candidate information from this resume PDF and output as JSON.\n",
        "Use this structure:\n",
        "{\n",
        "  \"name\": \"\",\n",
        "  \"email\": \"\",\n",
        "  \"phone\": \"\",\n",
        "  \"summary\": \"\",\n",
        "  \"skills\": [],\n",
        "  \"education\": [\n",
        "    {\"school\": \"\", \"degree\": \"\", \"start_year\": \"\", \"end_year\": \"\"}\n",
        "  ],\n",
        "  \"experience\": [\n",
        "    {\"company\": \"\", \"position\": \"\", \"start_date\": \"\", \"end_date\": \"\", \"description\": \"\"}\n",
        "  ]\n",
        "}\n",
        "If a field is missing, leave it empty or null. For 'summary', generate a brief summary of the candidate's profile based on the CV content. Do not include extra text outside JSON.\n",
        "\"\"\"\n",
        "\n",
        "# Send to Gemini with Pydantic schema ---\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=[\n",
        "        types.Part.from_bytes(data=pdf_bytes, mime_type=\"application/pdf\"),\n",
        "        prompt\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=CandidateProfile,  # Use the Pydantic schema here\n",
        "        temperature=0.0,\n",
        "        max_output_tokens=3000,\n",
        "    ),\n",
        ")\n",
        "\n",
        "#Parse output with Pydantic validation ---\n",
        "raw = response.text\n",
        "print(\"\\nRaw output:\\n\", raw)\n",
        "\n",
        "try:\n",
        "    # First parse the JSON\n",
        "    parsed_data = json.loads(raw)\n",
        "\n",
        "    # Then validate with Pydantic\n",
        "    candidate = CandidateProfile(**parsed_data)\n",
        "\n",
        "    print(\"\\n--- Extracted Resume (Validated) ---\")\n",
        "    print(\"Name:\", candidate.name)\n",
        "    print(\"Email:\", candidate.email)\n",
        "    print(\"Phone:\", candidate.phone)\n",
        "    print(\"Summary:\", candidate.summary)\n",
        "    print(\"Skills:\", candidate.skills)\n",
        "\n",
        "    print(\"\\nEducation:\")\n",
        "    for edu in candidate.education:\n",
        "        print(f\"  - {edu.degree} from {edu.school} ({edu.start_year}-{edu.end_year})\")\n",
        "\n",
        "    print(\"\\nExperience:\")\n",
        "    for exp in candidate.experience:\n",
        "        print(f\"  - {exp.position} at {exp.company} ({exp.start_date}-{exp.end_date})\")\n",
        "\n",
        "    # Convert back to JSON if needed\n",
        "    validated_json = candidate.model_dump_json(indent=2)\n",
        "    print(\"\\n--- Validated JSON Output ---\")\n",
        "    print(validated_json)\n",
        "\n",
        "except json.JSONDecodeError as e:\n",
        "    print(\"⚠️ JSON parse error:\", e)\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Pydantic validation error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfNVZFQpvdD-",
        "outputId": "da7a7989-3d1d-4b4d-eac2-cefde34e269b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raw output:\n",
            " {\n",
            "  \"name\": \"Daksana Harijeyan\",\n",
            "  \"email\": \"daksana2018@gmail.com\",\n",
            "  \"phone\": \"+94 77 150 6569\",\n",
            "  \"summary\": \"Highly skilled Machine Learning Engineer and Lecturer with expertise in designing and implementing end-to-end AutoML pipelines, developing AI/ML solutions for IoT sensor data, and building chatbots using RAG and Langchain frameworks. Proficient in Python, Docker, and various ML tasks, with experience in UI/UX design for ML workflows and teaching computer science subjects.\",\n",
            "  \"skills\": [\n",
            "    \"AWS\",\n",
            "    \"Bit bucket\",\n",
            "    \"Classification\",\n",
            "    \"Regression\",\n",
            "    \"Clustering and Anomaly detection algorithms\",\n",
            "    \"CrewAI\",\n",
            "    \"Deep learning\",\n",
            "    \"Docker\",\n",
            "    \"Exploratory Data Analysis\",\n",
            "    \"Firebase\",\n",
            "    \"Flask\",\n",
            "    \"Flutter\",\n",
            "    \"Git\",\n",
            "    \"IoT Sensor data handling\",\n",
            "    \"Java\",\n",
            "    \"Langchain\",\n",
            "    \"LangGraph\",\n",
            "    \"Machine Learning Pipeline\",\n",
            "    \"Microsoft SQL Server\",\n",
            "    \"Postman\",\n",
            "    \"Python\",\n",
            "    \"Retrieval-Augmented Generation\",\n",
            "    \"Spyder\",\n",
            "    \"SQLite\",\n",
            "    \"Statistical Inference\",\n",
            "    \"Timeseries analysis\",\n",
            "    \"Visual studio code\",\n",
            "    \"Academic Writing\",\n",
            "    \"Fast Learning\",\n",
            "    \"Literature review and Project Documentation\",\n",
            "    \"Presentation\",\n",
            "    \"Teaching\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"school\": \"University Of Moratuwa\",\n",
            "      \"degree\": \"MSc in Data Science & Artificial Intelligence\",\n",
            "      \"start_year\": \"01/2025\",\n",
            "      \"end_year\": \"Present\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"University Of Moratuwa\",\n",
            "      \"degree\": \"B.Sc Hons. In Information Technology\",\n",
            "      \"start_year\": \"01/2018\",\n",
            "      \"end_year\": \"12/2023\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"Deep Learning.AI\",\n",
            "      \"degree\": \"Neural Networks and Deep Learning\",\n",
            "      \"start_year\": \"02/2023\",\n",
            "      \"end_year\": \"03/2023\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"CIMA\",\n",
            "      \"degree\": \"CIMA Certificate in Business Accounting\",\n",
            "      \"start_year\": null,\n",
            "      \"end_year\": null\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": \"SenzMate IoT Intelligence\",\n",
            "      \"position\": \"Machine Learning Engineer (Remote)\",\n",
            "      \"start_date\": \"01/2022\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"description\": \"Defined the AutoML pipeline architecture, specifying data flows, input/output parameters, and API endpoints to ensure seamless interaction with frontend and other system components. Led requirement gathering from stakeholders, documented use cases, and ensured technical feasibility by aligning the AutoML solution with business objectives. Created UI workflow designs in Figma based on pipeline operations and collaborated with the UI/UX and software engineering teams to integrate backend functionality with user-facing elements. Implemented the end-to-end AutoML pipeline, developing backend services in Python that covered data preprocessing, model training, evaluation, and deployment in a Docker containerized environment. Extended the AutoML pipeline to support multiple ML tasks (regression, classification, clustering) with minimal UI adjustments, enabling reusable and scalable solutions. Successfully applied this pipeline to IoT sensor-based problems, building and deploying predictive models that solved real-world industrial challenges. Developed chatbots utilizing the RAG and Langchain frameworks, enhancing user interaction through exploratory data analysis and graph generations. Integrated LLM with RAG by exploring and implementing solutions using the LLMWARE library. Designed and executed algorithms for customer-specific projects. Worked with time series data for pattern classification in real-world use cases involving sensor data.\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"SenzMate IoT Intelligence\",\n",
            "      \"position\": \"Machine Learning Intern\",\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": \"Led AutoML UI/UX design with Figma and engineered RESTful API integration. Developed a Python-based ML pipeline from data ingestion to evaluation, emphasizing testing, debugging, and documentation.\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"DTPE campus\",\n",
            "      \"position\": \"Visiting Lecturer\",\n",
            "      \"start_date\": \"05/2025\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"description\": \"Teaching Object-Oriented Programming, Data Structures and Algorithms.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- Extracted Resume (Validated) ---\n",
            "Name: Daksana Harijeyan\n",
            "Email: daksana2018@gmail.com\n",
            "Phone: +94 77 150 6569\n",
            "Summary: Highly skilled Machine Learning Engineer and Lecturer with expertise in designing and implementing end-to-end AutoML pipelines, developing AI/ML solutions for IoT sensor data, and building chatbots using RAG and Langchain frameworks. Proficient in Python, Docker, and various ML tasks, with experience in UI/UX design for ML workflows and teaching computer science subjects.\n",
            "Skills: ['AWS', 'Bit bucket', 'Classification', 'Regression', 'Clustering and Anomaly detection algorithms', 'CrewAI', 'Deep learning', 'Docker', 'Exploratory Data Analysis', 'Firebase', 'Flask', 'Flutter', 'Git', 'IoT Sensor data handling', 'Java', 'Langchain', 'LangGraph', 'Machine Learning Pipeline', 'Microsoft SQL Server', 'Postman', 'Python', 'Retrieval-Augmented Generation', 'Spyder', 'SQLite', 'Statistical Inference', 'Timeseries analysis', 'Visual studio code', 'Academic Writing', 'Fast Learning', 'Literature review and Project Documentation', 'Presentation', 'Teaching']\n",
            "\n",
            "Education:\n",
            "  - MSc in Data Science & Artificial Intelligence from University Of Moratuwa (01/2025-Present)\n",
            "  - B.Sc Hons. In Information Technology from University Of Moratuwa (01/2018-12/2023)\n",
            "  - Neural Networks and Deep Learning from Deep Learning.AI (02/2023-03/2023)\n",
            "  - CIMA Certificate in Business Accounting from CIMA (None-None)\n",
            "\n",
            "Experience:\n",
            "  - Machine Learning Engineer (Remote) at SenzMate IoT Intelligence (01/2022-Present)\n",
            "  - Machine Learning Intern at SenzMate IoT Intelligence (None-None)\n",
            "  - Visiting Lecturer at DTPE campus (05/2025-Present)\n",
            "\n",
            "--- Validated JSON Output ---\n",
            "{\n",
            "  \"name\": \"Daksana Harijeyan\",\n",
            "  \"email\": \"daksana2018@gmail.com\",\n",
            "  \"phone\": \"+94 77 150 6569\",\n",
            "  \"summary\": \"Highly skilled Machine Learning Engineer and Lecturer with expertise in designing and implementing end-to-end AutoML pipelines, developing AI/ML solutions for IoT sensor data, and building chatbots using RAG and Langchain frameworks. Proficient in Python, Docker, and various ML tasks, with experience in UI/UX design for ML workflows and teaching computer science subjects.\",\n",
            "  \"skills\": [\n",
            "    \"AWS\",\n",
            "    \"Bit bucket\",\n",
            "    \"Classification\",\n",
            "    \"Regression\",\n",
            "    \"Clustering and Anomaly detection algorithms\",\n",
            "    \"CrewAI\",\n",
            "    \"Deep learning\",\n",
            "    \"Docker\",\n",
            "    \"Exploratory Data Analysis\",\n",
            "    \"Firebase\",\n",
            "    \"Flask\",\n",
            "    \"Flutter\",\n",
            "    \"Git\",\n",
            "    \"IoT Sensor data handling\",\n",
            "    \"Java\",\n",
            "    \"Langchain\",\n",
            "    \"LangGraph\",\n",
            "    \"Machine Learning Pipeline\",\n",
            "    \"Microsoft SQL Server\",\n",
            "    \"Postman\",\n",
            "    \"Python\",\n",
            "    \"Retrieval-Augmented Generation\",\n",
            "    \"Spyder\",\n",
            "    \"SQLite\",\n",
            "    \"Statistical Inference\",\n",
            "    \"Timeseries analysis\",\n",
            "    \"Visual studio code\",\n",
            "    \"Academic Writing\",\n",
            "    \"Fast Learning\",\n",
            "    \"Literature review and Project Documentation\",\n",
            "    \"Presentation\",\n",
            "    \"Teaching\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"school\": \"University Of Moratuwa\",\n",
            "      \"degree\": \"MSc in Data Science & Artificial Intelligence\",\n",
            "      \"start_year\": \"01/2025\",\n",
            "      \"end_year\": \"Present\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"University Of Moratuwa\",\n",
            "      \"degree\": \"B.Sc Hons. In Information Technology\",\n",
            "      \"start_year\": \"01/2018\",\n",
            "      \"end_year\": \"12/2023\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"Deep Learning.AI\",\n",
            "      \"degree\": \"Neural Networks and Deep Learning\",\n",
            "      \"start_year\": \"02/2023\",\n",
            "      \"end_year\": \"03/2023\"\n",
            "    },\n",
            "    {\n",
            "      \"school\": \"CIMA\",\n",
            "      \"degree\": \"CIMA Certificate in Business Accounting\",\n",
            "      \"start_year\": null,\n",
            "      \"end_year\": null\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": \"SenzMate IoT Intelligence\",\n",
            "      \"position\": \"Machine Learning Engineer (Remote)\",\n",
            "      \"start_date\": \"01/2022\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"description\": \"Defined the AutoML pipeline architecture, specifying data flows, input/output parameters, and API endpoints to ensure seamless interaction with frontend and other system components. Led requirement gathering from stakeholders, documented use cases, and ensured technical feasibility by aligning the AutoML solution with business objectives. Created UI workflow designs in Figma based on pipeline operations and collaborated with the UI/UX and software engineering teams to integrate backend functionality with user-facing elements. Implemented the end-to-end AutoML pipeline, developing backend services in Python that covered data preprocessing, model training, evaluation, and deployment in a Docker containerized environment. Extended the AutoML pipeline to support multiple ML tasks (regression, classification, clustering) with minimal UI adjustments, enabling reusable and scalable solutions. Successfully applied this pipeline to IoT sensor-based problems, building and deploying predictive models that solved real-world industrial challenges. Developed chatbots utilizing the RAG and Langchain frameworks, enhancing user interaction through exploratory data analysis and graph generations. Integrated LLM with RAG by exploring and implementing solutions using the LLMWARE library. Designed and executed algorithms for customer-specific projects. Worked with time series data for pattern classification in real-world use cases involving sensor data.\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"SenzMate IoT Intelligence\",\n",
            "      \"position\": \"Machine Learning Intern\",\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": \"Led AutoML UI/UX design with Figma and engineered RESTful API integration. Developed a Python-based ML pipeline from data ingestion to evaluation, emphasizing testing, debugging, and documentation.\"\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"DTPE campus\",\n",
            "      \"position\": \"Visiting Lecturer\",\n",
            "      \"start_date\": \"05/2025\",\n",
            "      \"end_date\": \"Present\",\n",
            "      \"description\": \"Teaching Object-Oriented Programming, Data Structures and Algorithms.\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-7ENi6JL5zby"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}